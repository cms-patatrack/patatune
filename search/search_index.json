{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PATATUNE","text":"<p>A Framework for Metaheuristic Multi-Objective Optimization for High Energy Physics</p> <p> </p> <p>Documentation: https://cms-patatrack.github.io/patatune</p> <p>Source code: https://github.com/cms-patatrack/patatune</p> <p>PATATUNE is a Python package that provides a framework for multi-objective optimization algorithms, including the Multi-Objective Particle Swarm Optimization (MOPSO) method. Its primary purpose is to automate the optimization of the parameters of user-defined functions. The package has been developed with the needs of CMS and Patatrack in mind.</p> <p>The key features are:</p> <ul> <li>Easy to use and learn.</li> <li>Pluggable Multi-objective optimization model with Multi-Objective Particle Swarm Optimization implemented via the <code>MOPSO</code> class.</li> <li>Multiple objective definition supported, for any user-defined objective function.</li> <li>Support for different parameter types (int, float, bool).</li> <li>Built-in metrics for convergence/quality assessment: Generational Distance, Inverted GD, Hypervolume.</li> <li>Persistence and checkpointing via <code>FileManager</code> (save/load pickle, CSV, Zarr); supports resuming runs and per-iteration history export.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>PATATUNE is available on PyPi.</p> <p>To install it you can simply run:</p> <pre><code>pip install patatune\n</code></pre> <p>If you want to use the latest development version on the main branch:</p> <ol> <li>Clone this repository</li> <li>Navigate into the project directory</li> <li> <p>Install the package and its dependencies using pip:</p> <p><pre><code>pip install .\n</code></pre> You can install a project in \u201ceditable\u201d or \u201cdevelop\u201d mode while you\u2019re working on it. When installed as editable, a project can be edited in-place without reinstallation:</p> </li> </ol> <pre><code>pip install -e .\n</code></pre>"},{"location":"#requirements","title":"Requirements","text":"<p>PATATUNE is written for Python 3.9+ and depends on a small set of scientific Python packages.  The following are required to run the library:</p> <ul> <li>numpy</li> <li>dill</li> </ul> <p>Optional functionality is provided by extras:</p> <ul> <li>numba (optional \u2014 JIT acceleration)</li> <li>zarr==2.* (optional \u2014 save/load history in Zarr format)</li> </ul> <p>These dependencies are declared in <code>pyproject.toml</code> and can be installed with pip (see Installation below). If you need the optional extras, install with <code>extra</code>:</p> <pre><code>pip install patatune[extra]\n</code></pre> <p>The additional example require additional libraries (matplotlib, pandas). If you want to run them, install with <code>tests</code>:</p> <p><pre><code>pip install patatune[tests]\n</code></pre> or, to include every optional dependecy:</p> <pre><code>pip install patatune[all]\n</code></pre>"},{"location":"#example","title":"Example","text":"<p>Currently the package provides the <code>patatune</code> module that defines an optimization algorithm: <code>MOPSO</code>. PATATUNE relies on a few helper classes to handle configuration and the objective functions. To use this module in your Python projects:</p> <ol> <li> <p>Import the required modules:</p> <pre><code>import patatune\n</code></pre> </li> <li> <p>Define the objective function to be optimized. i.e.:</p> <pre><code>def f1(x):\n    return 4 * x[0]**2 + 4 * x[1]**2\n\n\ndef f2(x):\n    return (x[0] - 5)**2 + (x[1] - 5)**2\n\nobjectives = patatune.ElementWiseObjective([f1, f2])\n</code></pre> </li> <li> <p>Define the boundaries of the parameters:</p> <pre><code>lb = [0.0, 0.0]\nub = [5.0, 3.0]\n</code></pre> </li> <li> <p>Create the MOPSO object with the configuration of the algorithm</p> <pre><code>mopso = patatune.MOPSO( objectives,\n                        lower_bounds=lb, upper_bounds=ub,\n                        num_particles=50,\n                        inertia_weight=0.4, cognitive_coefficient=1.5, social_coefficient=2)\n</code></pre> </li> <li> <p>Run the optimization algorithm</p> <pre><code>pareto = mopso.optimize(num_iterations = 100)\n</code></pre> </li> </ol> <p>The output will be the archive of optimal solutions found by the algorithm after 100 iterations.</p> <p>The output is a Python list containing Particle objects (instances of <code>patatune.mopso.particle.Particle</code>).  You can easily extract a compact representation from the returned list. For example:</p> <pre><code>for p in pareto:\n    print(\"position:\", p.position, \"fitness:\", p.fitness)\n</code></pre> <p>Example printed output:</p> <pre><code>id: 0  position: [1.8 1.6] fitness: [ 23.5 21.6]\nid: 49 position: [0.0 0.0] fitness: [ 0.   50. ]\nid: 18 position: [1.0 1.0] fitness: [ 8.3  31.7]\nid: 29 position: [5.0 3.0] fitness: [ 136. 4.  ]\nid: 16 position: [0.0 0.0] fitness: [ 0.   50. ]\n...\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome. If you want to contribute, please follow the Contribution guidelines.</p>"},{"location":"#license","title":"License","text":"<p>PATATUNE is distributed under the MPL 2.0 License. Feel free to use, modify, and distribute the code following the terms of the license.  </p>"},{"location":"api/","title":"PATATUNE Reference","text":"<p>This reference manual details functions, modules, and objects included in PATATUNE, describing what they are and what they do.</p> <p></p> <p>PATATUNE A Python framework for Metaheuristic Multi-Objective Optimization</p> <p>Modules:</p> <ul> <li> <code>metrics</code>           \u2013            <p>Module implementing various multi-objective optimization metrics.</p> </li> <li> <code>mopso</code>           \u2013            <p>Module implementing the Multi-Objective Particle Swarm Optimization (MOPSO) algorithm.</p> </li> <li> <code>objective</code>           \u2013            <p>Objective classes for multi-objective optimization.</p> </li> <li> <code>optimizer</code>           \u2013            <p>Optimizer module for patatune.</p> </li> <li> <code>util</code>           \u2013            <p>Utility functions and classes for Patatune.</p> </li> </ul>"},{"location":"api/#patatune.metrics","title":"metrics","text":"<p>Module implementing various multi-objective optimization metrics.</p> <p>Functions:</p> <ul> <li> <code>generational_distance</code>             \u2013              <p>Calculates the generational distance metric, for any dimension of the pareto front.</p> </li> <li> <code>hypervolume_indicator</code>             \u2013              <p>Calculates the hypervolume indicator metric, for any dimension of the pareto front.</p> </li> <li> <code>inverted_generational_distance</code>             \u2013              <p>Calculates the inverted generational distance metric, for any dimension of the pareto front.</p> </li> <li> <code>nds</code>             \u2013              <p>Returns the non-dominated set from the given front. </p> </li> <li> <code>wfg</code>             \u2013              <p>WFG algorithm for hypervolume calculation</p> </li> </ul>"},{"location":"api/#patatune.metrics.generational_distance","title":"generational_distance","text":"<pre><code>generational_distance(pareto_front, reference_front)\n</code></pre> <p>Calculates the generational distance metric, for any dimension of the pareto front.</p> <p>The generational distance (GD) measures the average distance of points in the obtained Pareto front to the nearest point in the true Pareto front.</p> <p>Parameters:</p> <ul> <li> <code>pareto_front</code>               (<code>ndarray</code>)           \u2013            <p>Represents the pareto front obtained from the optimization algorithm.</p> </li> <li> <code>reference_front</code>               (<code>ndarray</code>)           \u2013            <p>Represents the true pareto front.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The generational distance metric value.</p> </li> </ul>"},{"location":"api/#patatune.metrics.hypervolume_indicator","title":"hypervolume_indicator","text":"<pre><code>hypervolume_indicator(pareto_front, reference_point, reference_hv=1, max_evaluations=10000000)\n</code></pre> <p>Calculates the hypervolume indicator metric, for any dimension of the pareto front.</p> <p>The hypervolume indicator (HV) measures the volume of the objective space dominated by the obtained Pareto front and bounded by a reference point.</p> <p>Parameters:</p> <ul> <li> <code>pareto_front</code>               (<code>ndarray</code>)           \u2013            <p>Represents the pareto front obtained from the optimization algorithm.</p> </li> <li> <code>reference_point</code>               (<code>list or ndarray</code>)           \u2013            <p>A reference point in the objective space, typically chosen to be worse than any point in the pareto front.</p> </li> <li> <code>reference_hv</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>The hypervolume of the reference front for normalization (default: 1).</p> </li> <li> <code>max_evaluations</code>               (<code>int</code>, default:                   <code>10000000</code> )           \u2013            <p>Maximum number of evaluations to perform during hypervolume calculation (default: 10,000,000). Maximum number of evaluations to perform during hypervolume calculation (default: 10,000,000).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The hypervolume indicator metric value normalized by the reference hypervolume.</p> </li> </ul>"},{"location":"api/#patatune.metrics.inverted_generational_distance","title":"inverted_generational_distance","text":"<pre><code>inverted_generational_distance(pareto_front, reference_front)\n</code></pre> <p>Calculates the inverted generational distance metric, for any dimension of the pareto front.</p> <p>The inverted generational distance (IGD) measures the average distance of points in the true Pareto front to the nearest point in the obtained Pareto front.</p> <p>Parameters:</p> <ul> <li> <code>pareto_front</code>               (<code>ndarray</code>)           \u2013            <p>Represents the pareto front obtained from the optimization algorithm.</p> </li> <li> <code>reference_front</code>               (<code>ndarray</code>)           \u2013            <p>Represents the true pareto front.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The inverted generational distance metric value.</p> </li> </ul>"},{"location":"api/#patatune.metrics.nds","title":"nds","text":"<pre><code>nds(front)\n</code></pre> <p>Returns the non-dominated set from the given front. </p> <p>Uses the get_dominated utility function to identify dominated points and filters them out.</p> <p>Parameters:</p> <ul> <li> <code>front</code>               (<code>ndarray</code>)           \u2013            <p>Represents a set of points in the objective space.</p> </li> </ul> <p>Returns:     (np.ndarray): The non-dominated subset of the input front.</p>"},{"location":"api/#patatune.metrics.wfg","title":"wfg","text":"<pre><code>wfg(pareto_front, reference_point, counter, max_evaluations)\n</code></pre> <p>WFG algorithm for hypervolume calculation Reference: While, L., Bradstreet, L., &amp; Barone, L. (2012). A fast way of calculating exact hypervolumes. IEEE Transactions on Evolutionary Computation, 16(1), 86-95. DOI: 10.1109/TEVC.2010.2077298</p> <p>Parameters:</p> <ul> <li> <code>pareto_front</code>               (<code>ndarray</code>)           \u2013            <p>Represents the pareto front obtained from the optimization algorithm.</p> </li> <li> <code>reference_point</code>               (<code>list or ndarray</code>)           \u2013            <p>A reference point in the objective space, typically chosen to be worse than any point in the pareto front.</p> </li> <li> <code>counter</code>               (<code>list</code>)           \u2013            <p>A list containing a single integer to keep track of the number of evaluations performed.</p> </li> <li> <code>max_evaluations</code>               (<code>int</code>)           \u2013            <p>Maximum number of evaluations to perform during hypervolume calculation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The hypervolume of the pareto front with respect to the reference point.</p> </li> </ul> Note <p>Optionally uses numba's njit for performance optimization.</p>"},{"location":"api/#patatune.mopso","title":"mopso","text":"<p>Module implementing the Multi-Objective Particle Swarm Optimization (MOPSO) algorithm.</p> <p>Modules:</p> <ul> <li> <code>mopso</code>           \u2013            <p>Multi-Objective Particle Swarm Optimization (MOPSO) algorithm implementation.</p> </li> <li> <code>particle</code>           \u2013            <p>Module defining the Particle class for the MOPSO algorithm.</p> </li> </ul>"},{"location":"api/#patatune.mopso.mopso","title":"mopso","text":"<p>Multi-Objective Particle Swarm Optimization (MOPSO) algorithm implementation.</p> <p>Classes:</p> <ul> <li> <code>MOPSO</code>           \u2013            <p>Multi-Objective Particle Swarm Optimization (MOPSO) algorithm.  </p> </li> </ul>"},{"location":"api/#patatune.mopso.mopso.MOPSO","title":"MOPSO","text":"<pre><code>MOPSO(objective, lower_bounds, upper_bounds, param_names=None, num_particles=50, inertia_weight=0.5, cognitive_coefficient=1, social_coefficient=1, initial_particles_position='random', default_point=None, exploring_particles=False, topology='random', max_pareto_length=-1)\n</code></pre> <p>               Bases: <code>Optimizer</code></p> <p>Multi-Objective Particle Swarm Optimization (MOPSO) algorithm.  </p> <p>The MOPSO class implements the MOPSO algorithm for multi-objective optimization problems. It inherits from the base Optimizer class and provides methods for initializing particles, updating their positions and velocities, evaluating their fitness, and maintaining the Pareto front.</p> <p>Attributes:</p> <ul> <li> <code>objective</code>               (<code>Objective</code>)           \u2013            <p>The functions to optimize.</p> </li> <li> <code>lower_bounds</code>               (<code>list</code>)           \u2013            <p>List of lower bounds for each parameter.</p> </li> <li> <code>upper_bounds</code>               (<code>list</code>)           \u2013            <p>List of upper bounds for each parameter. lower and upper bounds are used to check the type of each parameter (int, float, bool)</p> </li> <li> <code>param_names</code>               (<code>list</code>)           \u2013            <p>List of parameter names.</p> </li> <li> <code>num_particles</code>               (<code>int</code>)           \u2013            <p>Number of particles in the swarm.</p> </li> <li> <code>inertia_weight</code>               (<code>float</code>)           \u2013            <p>Inertia weight for velocity update.</p> </li> <li> <code>cognitive_coefficient</code>               (<code>float</code>)           \u2013            <p>Cognitive coefficient for velocity update.</p> </li> <li> <code>social_coefficient</code>               (<code>float</code>)           \u2013            <p>Social coefficient for velocity update.</p> </li> <li> <code>initial_particles_position</code>               (<code>str</code>)           \u2013            <p>Method for initializing particle positions. Options are <code>lower_bounds</code>, <code>upper_bounds</code>, <code>random</code>, <code>gaussian</code>.</p> <ul> <li> <p>if <code>lower_bounds</code>, all particles are initialized at the lower bounds;</p> </li> <li> <p>if <code>upper_bounds</code>, all particles are initialized at the upper bounds;</p> </li> <li> <p>if <code>random</code>, particles are initialized randomly within the bounds;</p> </li> <li> <p>if <code>gaussian</code>, particles are initialized using a truncated Gaussian distribution centered around default_point.</p> </li> </ul> </li> <li> <code>default_point</code>               (<code>list</code>)           \u2013            <p>Default point for <code>gaussian</code> initialization.</p> <ul> <li>if None, the center between lower and upper bounds is used.</li> </ul> </li> <li> <code>exploring_particles</code>               (<code>bool</code>)           \u2013            <p>If True, particles that do not improve for a certain number of iterations are scattered.</p> </li> <li> <code>topology</code>               (<code>str</code>)           \u2013            <p>Topology for social interaction among particles. Options are <code>random</code>, <code>lower_weighted_crowding_distance</code>, <code>higher_weighted_crowding_distance</code>, <code>round_robin</code>.</p> <p>See Particle.get_pareto_leader for more information.</p> </li> <li> <code>max_pareto_length</code>               (<code>int</code>)           \u2013            <p>Maximum length of the Pareto front. If -1, no limit is applied.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>calculate_crowding_distance</code>             \u2013              <p>Calculates the crowding distance for each particle in the Pareto front.</p> </li> <li> <code>check_types</code>             \u2013              <p>Check that lower_bounds and upper_bounds have acceptable types and are consistent.</p> </li> <li> <code>export_state</code>             \u2013              <p>Exports the current state of the MOPSO optimizer to CSV files.</p> </li> <li> <code>get_metric</code>             \u2013              <p>Calculates a specified metric for the current Pareto front.</p> </li> <li> <code>load_state</code>             \u2013              <p>Loads the MOPSO optimizer state from a checkpoint file.</p> </li> <li> <code>optimize</code>             \u2013              <p>Runs the MOPSO optimization process for a specified number of iterations.</p> </li> <li> <code>save_state</code>             \u2013              <p>Saves the current state of the MOPSO optimizer to a checkpoint file.</p> </li> <li> <code>scatter_particle</code>             \u2013              <p>Scatters a particle that has not improved for a certain number of iterations.</p> </li> <li> <code>step</code>             \u2013              <p>Performs a single optimization step in the MOPSO algorithm.</p> </li> <li> <code>update_pareto_front</code>             \u2013              <p>Updates the Pareto front based on the current particles' fitness.</p> </li> </ul>"},{"location":"api/#patatune.mopso.mopso.MOPSO.calculate_crowding_distance","title":"calculate_crowding_distance","text":"<pre><code>calculate_crowding_distance(pareto_front)\n</code></pre> <p>Calculates the crowding distance for each particle in the Pareto front.</p> <p>Parameters:</p> <ul> <li> <code>pareto_front</code>               (<code>list</code>)           \u2013            <p>List of particles representing the current Pareto front.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>A dictionary mapping each particle in the Pareto front to its crowding distance.</p> </li> </ul>"},{"location":"api/#patatune.mopso.mopso.MOPSO.check_types","title":"check_types","text":"<pre><code>check_types()\n</code></pre> <p>Check that lower_bounds and upper_bounds have acceptable types and are consistent.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If any lower or upper bound has an unacceptable type,         or if lower_bounds and upper_bounds have inconsistent types.</p> </li> </ul>"},{"location":"api/#patatune.mopso.mopso.MOPSO.export_state","title":"export_state","text":"<pre><code>export_state()\n</code></pre> <p>Exports the current state of the MOPSO optimizer to CSV files.</p> Uses the FileManager to export <ul> <li>the states of individual particles to 'checkpoint/individual_states.csv'</li> <li>the current Pareto front to 'checkpoint/pareto_front.csv'.</li> </ul>"},{"location":"api/#patatune.mopso.mopso.MOPSO.get_metric","title":"get_metric","text":"<pre><code>get_metric(metric)\n</code></pre> <p>Calculates a specified metric for the current Pareto front.</p> <p>For example: <pre><code>mopso.get_metric(patatune.metrics.generational_distance)\n</code></pre></p> <p>Parameters:</p> <ul> <li> <code>metric</code>               (<code>function</code>)           \u2013            <p>A metric function that takes two arguments: the Pareto front and the reference front.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The calculated metric value.</p> </li> </ul>"},{"location":"api/#patatune.mopso.mopso.MOPSO.load_state","title":"load_state","text":"<pre><code>load_state()\n</code></pre> <p>Loads the MOPSO optimizer state from a checkpoint file.</p> <p>Uses the FileManager to deserialize and restore the MOPSO object from 'checkpoint/mopso.pkl'.</p>"},{"location":"api/#patatune.mopso.mopso.MOPSO.optimize","title":"optimize","text":"<pre><code>optimize(num_iterations=100, max_iterations_without_improvement=None)\n</code></pre> <p>Runs the MOPSO optimization process for a specified number of iterations.</p> <p>Uses the <code>step</code> method to perform optimization steps and manages the overall optimization loop.</p> <p>Parameters:</p> <ul> <li> <code>num_iterations</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>Total number of iterations to perform.</p> </li> <li> <code>max_iterations_without_improvement</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Maximum number of iterations a particle can go without improvement before being scattered. If None, no scattering is performed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>The final Pareto front after optimization.</p> </li> </ul>"},{"location":"api/#patatune.mopso.mopso.MOPSO.save_state","title":"save_state","text":"<pre><code>save_state()\n</code></pre> <p>Saves the current state of the MOPSO optimizer to a checkpoint file.</p> <p>Uses the FileManager to serialize and save the MOPSO object to 'checkpoint/mopso.pkl'.</p>"},{"location":"api/#patatune.mopso.mopso.MOPSO.scatter_particle","title":"scatter_particle","text":"<pre><code>scatter_particle(particle: Particle)\n</code></pre> <p>Scatters a particle that has not improved for a certain number of iterations.</p> <p>The particle's velocity is adjusted to move it towards less crowded areas of the search space.</p> <p>Parameters:</p> <ul> <li> <code>particle</code>               (<code>Particle</code>)           \u2013            <p>The particle to be scattered.</p> </li> </ul>"},{"location":"api/#patatune.mopso.mopso.MOPSO.step","title":"step","text":"<pre><code>step(max_iterations_without_improvement=None)\n</code></pre> <p>Performs a single optimization step in the MOPSO algorithm.</p> <p>Parameters:</p> <ul> <li> <code>max_iterations_without_improvement</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Maximum number of iterations a particle can go without improvement before being scattered. If None, no scattering is performed.</p> </li> </ul>"},{"location":"api/#patatune.mopso.mopso.MOPSO.update_pareto_front","title":"update_pareto_front","text":"<pre><code>update_pareto_front()\n</code></pre> <p>Updates the Pareto front based on the current particles' fitness.</p> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>A dictionary mapping each particle in the Pareto front to its crowding distance.</p> </li> </ul>"},{"location":"api/#patatune.mopso.particle","title":"particle","text":"<p>Module defining the Particle class for the MOPSO algorithm.</p> <p>Classes:</p> <ul> <li> <code>Particle</code>           \u2013            <p>Class representing a particle in the MOPSO algorithm.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>boltzmann</code>             \u2013              <p>Computes a probability distribution function (PDF) based on crowding distances.</p> </li> <li> <code>round_robin_topology</code>             \u2013              <p>Selects a leader particle from the Pareto front in a round-robin fashion.</p> </li> <li> <code>weighted_crowding_distance_topology</code>             \u2013              <p>Selects a leader particle from the Pareto front based on crowding distances.</p> </li> </ul>"},{"location":"api/#patatune.mopso.particle.Particle","title":"Particle","text":"<pre><code>Particle(lower_bound, num_objectives, num_particles, id, topology)\n</code></pre> <p>Class representing a particle in the MOPSO algorithm.</p> <p>Attributes:</p> <ul> <li> <code>position</code>               (<code>ndarray</code>)           \u2013            <p>Current position of the particle in the search space.</p> </li> <li> <code>num_objectives</code>               (<code>int</code>)           \u2013            <p>Number of objectives in the optimization problem.</p> </li> <li> <code>num_particles</code>               (<code>int</code>)           \u2013            <p>Total number of particles in the swarm.</p> </li> <li> <code>velocity</code>               (<code>ndarray</code>)           \u2013            <p>Current velocity of the particle.</p> </li> <li> <code>fitness</code>               (<code>ndarray</code>)           \u2013            <p>Current fitness values of the particle for each objective.</p> </li> <li> <code>local_best_fitnesses</code>               (<code>list</code>)           \u2013            <p>List of local best fitness values found by the particle.</p> </li> <li> <code>local_best_positions</code>               (<code>list</code>)           \u2013            <p>List of positions corresponding to the local best fitnesses.</p> </li> <li> <code>iterations_with_no_improvement</code>               (<code>int</code>)           \u2013            <p>Counter for iterations without improvement.</p> </li> <li> <code>id</code>               (<code>int</code>)           \u2013            <p>Unique identifier for the particle.</p> </li> <li> <code>topology</code>               (<code>str</code>)           \u2013            <p>Topology strategy for selecting global best in the swarm.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>get_pareto_leader</code>             \u2013              <p>Selects a leader particle from the Pareto front based on the specified topology.</p> </li> <li> <code>set_fitness</code>             \u2013              <p>Sets the fitness of the particle and updates its local best if necessary.</p> </li> <li> <code>set_position</code>             \u2013              <p>Sets the position of the particle.</p> </li> <li> <code>set_state</code>             \u2013              <p>Sets the complete state of the particle.</p> </li> <li> <code>update_best</code>             \u2013              <p>Updates the local best fitnesses and positions of the particle based on its current fitness.</p> </li> <li> <code>update_position</code>             \u2013              <p>Updates the position of the particle based on its velocity and the problem boundaries.</p> </li> <li> <code>update_velocity</code>             \u2013              <p>Updates the velocity of the particle based on its local best and the global best.</p> </li> </ul>"},{"location":"api/#patatune.mopso.particle.Particle.get_pareto_leader","title":"get_pareto_leader","text":"<pre><code>get_pareto_leader(pareto_front, crowding_distances)\n</code></pre> <p>Selects a leader particle from the Pareto front based on the specified topology.</p> <p>If the topology is \"random\", a random particle from the Pareto front is selected. If the topology is \"lower_weighted_crowding_distance\", a particle is selected with a probability inversely proportional to its crowding distance calling the weighted_crowding_distance_topology function. If the topology is \"higher_weighted_crowding_distance\", a particle is selected with a probability proportional to its crowding distance calling the weighted_crowding_distance_topology function. If the topology is \"round_robin\", particles are selected in a round-robin fashion based on the particle's ID calling the round_robin_topology function.</p> <p>Parameters:</p> <ul> <li> <code>pareto_front</code>               (<code>list</code>)           \u2013            <p>List of particles representing the current Pareto front.</p> </li> <li> <code>crowding_distances</code>               (<code>dict</code>)           \u2013            <p>Dictionary mapping particles to their crowding distances.</p> </li> </ul>"},{"location":"api/#patatune.mopso.particle.Particle.set_fitness","title":"set_fitness","text":"<pre><code>set_fitness(fitness)\n</code></pre> <p>Sets the fitness of the particle and updates its local best if necessary.</p> <p>Parameters:</p> <ul> <li> <code>fitness</code>               (<code>ndarray</code>)           \u2013            <p>New fitness values for the particle.</p> </li> </ul>"},{"location":"api/#patatune.mopso.particle.Particle.set_position","title":"set_position","text":"<pre><code>set_position(position)\n</code></pre> <p>Sets the position of the particle.</p> <p>Parameters:</p> <ul> <li> <code>position</code>               (<code>ndarray</code>)           \u2013            <p>New position for the particle.</p> </li> </ul>"},{"location":"api/#patatune.mopso.particle.Particle.set_state","title":"set_state","text":"<pre><code>set_state(velocity, position, best_position, fitness, best_fitness)\n</code></pre> <p>Sets the complete state of the particle.</p> <p>Parameters:</p> <ul> <li> <code>velocity</code>               (<code>ndarray</code>)           \u2013            <p>New velocity for the particle.</p> </li> <li> <code>position</code>               (<code>ndarray</code>)           \u2013            <p>New position for the particle.</p> </li> <li> <code>best_position</code>               (<code>list</code>)           \u2013            <p>New list of local best positions for the particle.</p> </li> <li> <code>fitness</code>               (<code>ndarray</code>)           \u2013            <p>New fitness values for the particle.</p> </li> <li> <code>best_fitness</code>               (<code>list</code>)           \u2013            <p>New list of local best fitness values for the particle.</p> </li> </ul>"},{"location":"api/#patatune.mopso.particle.Particle.update_best","title":"update_best","text":"<pre><code>update_best()\n</code></pre> <p>Updates the local best fitnesses and positions of the particle based on its current fitness.</p> <p>Uses the get_dominated utility function to identify non-dominated solutions. Resets the iterations_with_no_improvement counter if there is an improvement.</p>"},{"location":"api/#patatune.mopso.particle.Particle.update_position","title":"update_position","text":"<pre><code>update_position(lower_bound, upper_bound)\n</code></pre> <p>Updates the position of the particle based on its velocity and the problem boundaries.</p> <p>If the variable is of integer type, the new position is rounded. If the variable is of boolean type, the new position is determined by a threshold of 0.5.</p> <p>Parameters:</p> <ul> <li> <code>lower_bound</code>               (<code>ndarray</code>)           \u2013            <p>Lower bounds for each dimension of the search space.</p> </li> <li> <code>upper_bound</code>               (<code>ndarray</code>)           \u2013            <p>Upper bounds for each dimension of the search space.</p> </li> </ul>"},{"location":"api/#patatune.mopso.particle.Particle.update_velocity","title":"update_velocity","text":"<pre><code>update_velocity(pareto_front, crowding_distances, inertia_weight=0.5, cognitive_coefficient=1, social_coefficient=1)\n</code></pre> <p>Updates the velocity of the particle based on its local best and the global best.</p> <p>Parameters:</p> <ul> <li> <code>pareto_front</code>               (<code>list</code>)           \u2013            <p>List of particles representing the current Pareto front.</p> </li> <li> <code>crowding_distances</code>               (<code>dict</code>)           \u2013            <p>Dictionary mapping particles to their crowding distances.</p> </li> <li> <code>inertia_weight</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>Weight for the inertia component (default: 0.5).</p> </li> <li> <code>cognitive_coefficient</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Coefficient for the cognitive component (default: 1).</p> </li> <li> <code>social_coefficient</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Coefficient for the social component (default: 1).</p> </li> </ul>"},{"location":"api/#patatune.mopso.particle.boltzmann","title":"boltzmann","text":"<pre><code>boltzmann(crowding_distances, higher)\n</code></pre> <p>Computes a probability distribution function (PDF) based on crowding distances.</p> <p>Parameters:</p> <ul> <li> <code>crowding_distances</code>               (<code>dict</code>)           \u2013            <p>Dictionary mapping particles to their crowding distances.</p> </li> <li> <code>higher</code>               (<code>bool</code>)           \u2013            <p>If True, computes PDF favoring higher crowding distances.             If False, computes PDF favoring lower crowding distances.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>A list representing the probability distribution function for selecting particles.</p> </li> </ul>"},{"location":"api/#patatune.mopso.particle.round_robin_topology","title":"round_robin_topology","text":"<pre><code>round_robin_topology(pareto_front, id)\n</code></pre> <p>Selects a leader particle from the Pareto front in a round-robin fashion.</p> <p>The particle is selected based on its ID modulo the size of the Pareto front. If the ID exceeds the size of the Pareto front, it wraps around.</p> <p>Parameters:</p> <ul> <li> <code>pareto_front</code>               (<code>list</code>)           \u2013            <p>List of particles representing the current Pareto front.</p> </li> <li> <code>id</code>               (<code>int</code>)           \u2013            <p>Unique identifier for the particle.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Particle</code>           \u2013            <p>The selected leader particle from the Pareto front.</p> </li> </ul>"},{"location":"api/#patatune.mopso.particle.weighted_crowding_distance_topology","title":"weighted_crowding_distance_topology","text":"<pre><code>weighted_crowding_distance_topology(pareto_front, crowding_distances, higher)\n</code></pre> <p>Selects a leader particle from the Pareto front based on crowding distances.</p> <p>Parameters:</p> <ul> <li> <code>pareto_front</code>               (<code>list</code>)           \u2013            <p>List of particles representing the current Pareto front.</p> </li> <li> <code>crowding_distances</code>               (<code>dict</code>)           \u2013            <p>Dictionary mapping particles to their crowding distances.</p> </li> <li> <code>higher</code>               (<code>bool</code>)           \u2013            <p>If True, selects particles with higher crowding distances with higher probability.             If False, selects particles with lower crowding distances with higher probability.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Particle</code>           \u2013            <p>The selected leader particle from the Pareto front.</p> </li> </ul>"},{"location":"api/#patatune.objective","title":"objective","text":"<p>Objective classes for multi-objective optimization.</p> <p>Provides a base <code>Objective</code> and concrete implementations for element-wise, batched and asynchronous evaluations.</p> <p>Classes:</p> <ul> <li> <code>AsyncElementWiseObjective</code>           \u2013            <p>Asynchronous element-wise objective class.</p> </li> <li> <code>BatchObjective</code>           \u2013            <p>Batch objective class.</p> </li> <li> <code>ElementWiseObjective</code>           \u2013            <p>Element-wise objective class.</p> </li> <li> <code>Objective</code>           \u2013            <p>Base class for defining objective functions.</p> </li> </ul>"},{"location":"api/#patatune.objective.AsyncElementWiseObjective","title":"AsyncElementWiseObjective","text":"<pre><code>AsyncElementWiseObjective(objective_functions, num_objectives=None, directions=None, objective_names=None, true_pareto=None)\n</code></pre> <p>               Bases: <code>Objective</code></p> <p>Asynchronous element-wise objective class.</p> <p>Methods:</p> <ul> <li> <code>evaluate</code>             \u2013              <p>Passes each item one by one to each asynchronous objective function and collects the results.</p> </li> </ul>"},{"location":"api/#patatune.objective.AsyncElementWiseObjective.evaluate","title":"evaluate","text":"<pre><code>evaluate(items)\n</code></pre> <p>Passes each item one by one to each asynchronous objective function and collects the results.</p> <p>Parameters:</p> <ul> <li> <code>items</code>               (<code>list</code>)           \u2013            <p>List of parameter sets to evaluate of shape (num_particles, num_parameters).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>Array of shape (num_particles, num_objectives) with evaluated objective values.</p> </li> </ul>"},{"location":"api/#patatune.objective.BatchObjective","title":"BatchObjective","text":"<pre><code>BatchObjective(objective_functions, batch_size, num_objectives=None, directions=None, objective_names=None, true_pareto=None)\n</code></pre> <p>               Bases: <code>Objective</code></p> <p>Batch objective class.</p> <p>Inherits from the base Objective class and implements the evaluate method to evaluate each objective function on batches of items asynchronously.</p> <p>Attributes:     batch_size (int): Size of each batch for evaluation.</p> <p>Methods:</p> <ul> <li> <code>evaluate</code>             \u2013              <p>Passes items in batches to each objective function asynchronously and collects the results.</p> </li> </ul>"},{"location":"api/#patatune.objective.BatchObjective.evaluate","title":"evaluate","text":"<pre><code>evaluate(items)\n</code></pre> <p>Passes items in batches to each objective function asynchronously and collects the results.</p> <p>Parameters:</p> <ul> <li> <code>items</code>               (<code>list</code>)           \u2013            <p>List of parameter sets to evaluate of shape (num_particles, num_parameters).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>Array of shape (num_particles, num_objectives) with evaluated objective values.</p> </li> </ul>"},{"location":"api/#patatune.objective.ElementWiseObjective","title":"ElementWiseObjective","text":"<pre><code>ElementWiseObjective(objective_functions, num_objectives=None, directions=None, objective_names=None, true_pareto=None)\n</code></pre> <p>               Bases: <code>Objective</code></p> <p>Element-wise objective class.</p> <p>Inherits from the base Objective class and implements the evaluate method to evaluate each objective function on individual items.</p> <p>Methods:</p> <ul> <li> <code>evaluate</code>             \u2013              <p>Passes each item one by one to each objective function and collects the results.</p> </li> </ul>"},{"location":"api/#patatune.objective.ElementWiseObjective.evaluate","title":"evaluate","text":"<pre><code>evaluate(items)\n</code></pre> <p>Passes each item one by one to each objective function and collects the results.</p> <p>Parameters:</p> <ul> <li> <code>items</code>               (<code>list</code>)           \u2013            <p>List of parameter sets to evaluate of shape (num_particles, num_parameters).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>Array of shape (num_particles, num_objectives) with evaluated objective values.</p> </li> </ul>"},{"location":"api/#patatune.objective.Objective","title":"Objective","text":"<pre><code>Objective(objective_functions, num_objectives=None, directions=None, objective_names=None, true_pareto=None)\n</code></pre> <p>Base class for defining objective functions.</p> <p>The class is used to evaluate multiple objective functions for all particles simultaneously. The classes that inherit from this one should implement the <code>evaluate</code> method.</p> <p>Parameters:</p> <ul> <li> <code>objective_functions</code>               (<code>list | callable</code>)           \u2013            <p>A list of callables (or a single callable) that compute objective values.</p> </li> <li> <code>num_objectives</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Number of objectives. Defaults to <code>len(objective_functions)</code>.</p> </li> <li> <code>directions</code>               (<code>list[str]</code>, default:                   <code>None</code> )           \u2013            <p>List of 'minimize' or 'maximize' for each objective. Defaults to all 'minimize'.</p> </li> <li> <code>objective_names</code>               (<code>list[str]</code>, default:                   <code>None</code> )           \u2013            <p>Names for each objective.</p> </li> <li> <code>true_pareto</code>               (<code>callable</code>, default:                   <code>None</code> )           \u2013            <p>Function that returns the true Pareto front. Takes as input the number of points and returns a 2D array of shape <code>(num_points, num_objectives)</code>.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>evaluate</code>             \u2013              <p>Passes all items to each objective function and collects the results.</p> </li> </ul>"},{"location":"api/#patatune.objective.Objective.evaluate","title":"evaluate","text":"<pre><code>evaluate(items)\n</code></pre> <p>Passes all items to each objective function and collects the results.</p> <p>Parameters:</p> <ul> <li> <code>items</code>               (<code>list</code>)           \u2013            <p>List of parameter sets to evaluate with shape <code>(num_particles, num_parameters)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>Array of shape (num_particles, num_objectives) with evaluated objective values.</p> </li> </ul>"},{"location":"api/#patatune.optimizer","title":"optimizer","text":"<p>Optimizer module for patatune.</p> <p>This module contains the base <code>Optimizer</code> class that other optimizers in <code>patatune</code> should inherit from.</p> <p>Classes:</p> <ul> <li> <code>Optimizer</code>           \u2013            <p>Base class for optimization algorithms.</p> </li> </ul>"},{"location":"api/#patatune.optimizer.Optimizer","title":"Optimizer","text":"<pre><code>Optimizer()\n</code></pre> <p>Base class for optimization algorithms.</p> <p>Subclasses must implement <code>__init__</code>, <code>step</code>, and <code>optimize</code>.</p> <p>Raises:</p> <ul> <li> <code>NotImplementedError</code>             \u2013            <p>If methods are not implemented by subclasses.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>optimize</code>             \u2013              <p>Run the optimization loop.</p> </li> <li> <code>step</code>             \u2013              <p>Perform a single optimization step.</p> </li> </ul>"},{"location":"api/#patatune.optimizer.Optimizer.optimize","title":"optimize","text":"<pre><code>optimize()\n</code></pre> <p>Run the optimization loop.</p> <p>This method should coordinate repeated calls to :meth:<code>step</code> and any required setup/teardown.</p>"},{"location":"api/#patatune.optimizer.Optimizer.step","title":"step","text":"<pre><code>step()\n</code></pre> <p>Perform a single optimization step.</p> <p>Subclasses should update internal state (particles/parameters) in this method.</p>"},{"location":"api/#patatune.util","title":"util","text":"<p>Utility functions and classes for Patatune.</p> <p>This module provides various utility functions and classes used throughout the patatune package, including file management, logging, randomization, and dominance checking.</p> <p>The import of numba and zarr is optional to allow for flexibility in environments where these packages may not be installed.</p> <p>If numba is not installed, a dummy njit decorator is provided that does nothing.</p> <p>If zarr is not installed, a warning is logged and Zarr functionality is disabled.</p> <p>A default logger named \"patatune\" is configured with a custom formatter that adds colors based on log level. (See CustomFormatter for details.)</p> <p>A system-wide exception handler is set up to log uncaught exceptions using the patatune logger. (See handle_exception for details.)</p> <p>Classes:</p> <ul> <li> <code>CustomFormatter</code>           \u2013            <p>Custom logging formatter to add colors based on log level.</p> </li> <li> <code>FileManager</code>           \u2013            <p>File management utility class for saving and loading data in various formats.</p> </li> <li> <code>Randomizer</code>           \u2013            <p>Random number generator utility class.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>get_dominated</code>             \u2013              <p>Determine which particles are dominated within a population.</p> </li> <li> <code>handle_exception</code>             \u2013              <p>Global exception handler to log uncaught exceptions.</p> </li> </ul>"},{"location":"api/#patatune.util.CustomFormatter","title":"CustomFormatter","text":"<p>               Bases: <code>Formatter</code></p> <p>Custom logging formatter to add colors based on log level.</p> Notes <p>This class customizes the log format by adding color codes for different log levels. DEBUG and INFO messages are grey, WARNING messages are yellow, ERROR messages are red, and CRITICAL messages are bold red.</p> <p>The log is formatted as:</p> <p><code>%(asctime)s - %(name)s - %(levelname)s - %(message)s (%(filename)s:%(lineno)d)</code></p> <p>For example:</p> <p><code>2024-01-01 12:00:00,000 - patatune - WARNING - numba package is not installed. The code will run slower. (util.py:206)</code></p>"},{"location":"api/#patatune.util.FileManager","title":"FileManager","text":"<p>File management utility class for saving and loading data in various formats.</p> <p>This class provides methods to save and load data in CSV, JSON, Zarr, and Pickle formats.</p> <p>Attributes:</p> <ul> <li> <code>saving_enabled</code>               (<code>bool</code>)           \u2013            <p>Global flag to enable/disable saving.</p> </li> <li> <code>saving_csv_enabled</code>               (<code>bool</code>)           \u2013            <p>Flag to enable/disable CSV saving.</p> </li> <li> <code>saving_json_enabled</code>               (<code>bool</code>)           \u2013            <p>Flag to enable/disable JSON saving.</p> </li> <li> <code>saving_zarr_enabled</code>               (<code>bool</code>)           \u2013            <p>Flag to enable/disable Zarr saving.</p> </li> <li> <code>saving_pickle_enabled</code>               (<code>bool</code>)           \u2013            <p>Flag to enable/disable Pickle saving.</p> </li> <li> <code>loading_enabled</code>               (<code>bool</code>)           \u2013            <p>Global flag to enable/disable loading.</p> </li> <li> <code>headers_enabled</code>               (<code>bool</code>)           \u2013            <p>Flag to enable/disable headers when saving/loading CSV files.</p> </li> <li> <code>working_dir</code>               (<code>str</code>)           \u2013            <p>Directory where files will be saved/loaded from.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>load_csv</code>             \u2013              <p>Load data from a CSV file.</p> </li> <li> <code>load_json</code>             \u2013              <p>Load a dictionary from a JSON file.</p> </li> <li> <code>load_pickle</code>             \u2013              <p>Load an object from a Pickle file.</p> </li> <li> <code>save_csv</code>             \u2013              <p>Save a list of lists or 2D array to a CSV file.</p> </li> <li> <code>save_json</code>             \u2013              <p>Save a dictionary to a JSON file.</p> </li> <li> <code>save_pickle</code>             \u2013              <p>Save an object to a Pickle file.</p> </li> <li> <code>save_zarr</code>             \u2013              <p>Save a dictionary of arrays to a Zarr file.</p> </li> </ul>"},{"location":"api/#patatune.util.FileManager.load_csv","title":"load_csv  <code>classmethod</code>","text":"<pre><code>load_csv(filename)\n</code></pre> <p>Load data from a CSV file.</p> <p>The method loads data from a CSV file in the <code>working_dir</code> path. If <code>headers_enabled</code> is True, it assumes the first row contains headers.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>               (<code>str</code>)           \u2013            <p>Name of the input CSV file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>           \u2013            <p>A tuple containing the data as a NumPy array of floats and the headers (if any) as a NumPy array of strings.</p> </li> </ul>"},{"location":"api/#patatune.util.FileManager.load_json","title":"load_json  <code>classmethod</code>","text":"<pre><code>load_json(filename)\n</code></pre> <p>Load a dictionary from a JSON file.</p> <p>The method loads a dictionary from a JSON file in the <code>working_dir</code> path.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>               (<code>str</code>)           \u2013            <p>Name of the input JSON file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>The loaded dictionary.</p> </li> </ul>"},{"location":"api/#patatune.util.FileManager.load_pickle","title":"load_pickle  <code>classmethod</code>","text":"<pre><code>load_pickle(filename)\n</code></pre> <p>Load an object from a Pickle file.</p> <p>The method loads an object from a Pickle file in the <code>working_dir</code> path.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>               (<code>str</code>)           \u2013            <p>Name of the input Pickle file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>any</code>           \u2013            <p>The loaded object.</p> </li> </ul>"},{"location":"api/#patatune.util.FileManager.save_csv","title":"save_csv  <code>classmethod</code>","text":"<pre><code>save_csv(csv_list, filename='file.csv', headers=None)\n</code></pre> <p>Save a list of lists or 2D array to a CSV file.</p> <p>The method saves the data to a CSV file in the <code>working_dir</code> path. The CSV file is comma-separated and the data is written as floats with 18 decimal places and dot as decimal separator. The method creates the necessary directories if they do not exist. If headers are provided and <code>headers_enabled</code> is True, they will be written as the first row.</p> <p>Parameters:</p> <ul> <li> <code>csv_list</code>               (<code>list[list] | ndarray</code>)           \u2013            <p>Data to be saved.</p> </li> <li> <code>filename</code>               (<code>str</code>, default:                   <code>'file.csv'</code> )           \u2013            <p>Name of the output CSV file.</p> </li> <li> <code>headers</code>               (<code>list[str]</code>, default:                   <code>None</code> )           \u2013            <p>Column headers for the CSV file.</p> </li> </ul>"},{"location":"api/#patatune.util.FileManager.save_json","title":"save_json  <code>classmethod</code>","text":"<pre><code>save_json(dictionary, filename)\n</code></pre> <p>Save a dictionary to a JSON file.</p> <p>The method saves a dictionary to a JSON file in the <code>working_dir</code> path. It creates the necessary directories if they do not exist.</p> <p>Parameters:</p> <ul> <li> <code>dictionary</code>               (<code>dict</code>)           \u2013            <p>Dictionary to be saved.</p> </li> <li> <code>filename</code>               (<code>str</code>)           \u2013            <p>Name of the output JSON file.</p> </li> </ul>"},{"location":"api/#patatune.util.FileManager.save_pickle","title":"save_pickle  <code>classmethod</code>","text":"<pre><code>save_pickle(obj, filename)\n</code></pre> <p>Save an object to a Pickle file.</p> <p>The method saves an object to a Pickle file in the <code>working_dir</code> path. It creates the necessary directories if they do not exist.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>               (<code>any</code>)           \u2013            <p>The object to be saved.</p> </li> <li> <code>filename</code>               (<code>str</code>)           \u2013            <p>Name of the output Pickle file.</p> </li> </ul>"},{"location":"api/#patatune.util.FileManager.save_zarr","title":"save_zarr  <code>classmethod</code>","text":"<pre><code>save_zarr(obj, filename, **kwargs)\n</code></pre> <p>Save a dictionary of arrays to a Zarr file.</p> <p>The method saves a dictionary of arrays to a Zarr file in the <code>working_dir</code> path. It creates the necessary directories if they do not exist. The keys of the dictionary are used as group names in the Zarr file. If a key is an integer, it is prefixed with \"iteration_\" to form the group name. Additional attributes can be added to the root group via <code>kwargs</code>.</p> <p>Parameters:</p> <ul> <li> <code>obj</code>               (<code>dict</code>)           \u2013            <p>The dictionary of arrays to be saved.</p> </li> <li> <code>filename</code>               (<code>str</code>)           \u2013            <p>Name of the output Zarr file.</p> </li> <li> <code>**kwargs</code>           \u2013            <p>Additional attributes to be saved in the root group as key-value pairs where the key is the attribute name and the value is the attribute value.</p> </li> </ul>"},{"location":"api/#patatune.util.Randomizer","title":"Randomizer","text":"<p>Random number generator utility class.</p> <p>Implements a class-level random number generator using NumPy's default_rng. This class provides a shared random number generator that can be used throughout the package. Can be accessed via <code>Randomizer.rng</code>.</p> <p>For example, to set a seed: <pre><code>Randomizer.rng = np.random.default_rng(seed=42)\n</code></pre></p>"},{"location":"api/#patatune.util.get_dominated","title":"get_dominated","text":"<pre><code>get_dominated(particles, pareto_length)\n</code></pre> <p>Determine which particles are dominated within a population.</p> <p>A particle is considered dominated if there exists at least one other particle that is better or equal in all objectives and strictly better in at least one objective.</p> <p>Parameters:</p> <ul> <li> <code>particles</code>               (<code>ndarray</code>)           \u2013            <p>2-D array of objective values for each particle (shape: [n_particles, n_objectives]).</p> </li> <li> <code>pareto_length</code>               (<code>int</code>)           \u2013            <p>Number of particles considered part of the current Pareto set (these are skipped in comparisons).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>Boolean array of length <code>len(particles)</code> where True means the particle is dominated by at least one other particle.</p> </li> </ul> Notes <p>The function is decorated with a (possible) <code>njit</code> to allow optional numba acceleration.</p>"},{"location":"api/#patatune.util.handle_exception","title":"handle_exception","text":"<pre><code>handle_exception(exc_type, exc_value, exc_traceback)\n</code></pre> <p>Global exception handler to log uncaught exceptions.</p> <p>The function logs uncaught exceptions using the default patatune logger.</p> <p>Parameters:</p> <ul> <li> <code>exc_type</code>               (<code>type</code>)           \u2013            <p>The exception type.</p> </li> <li> <code>exc_value</code>               (<code>Exception</code>)           \u2013            <p>The exception instance.</p> </li> <li> <code>exc_traceback</code>               (<code>traceback</code>)           \u2013            <p>The traceback object.</p> </li> </ul>"},{"location":"user_guide/","title":"User Guide","text":"<p>Beyond what has been introduced in the Example, PATATUNE allows to fine tune the optimization process for the user.</p> <p>This involves the definition of the parameters to optimize, the definition of the optimization function, and the configuration of the optimization algorithms.</p> <p>In addition, several utilities are implemented to adapt to the user environment and workflow.</p> <p>The following documentation details the functionalities available and how to use them.</p>"},{"location":"user_guide/#parameters-definition","title":"Parameters definition","text":"<p>PATATUNE uses the lower and upper bound of the parameters to define the search space.</p> <p>In addition it deducts the parameters type from the bounds.</p> <p>One can define the parameters bounds as two lists:</p> <p><pre><code>lb = [0, 0., False]\nub = [5, 5., True]\n</code></pre> This define a parameter space with three parameters, where:</p> <ul> <li>the first parameter is an integer going from 0 (included) to 5 (included);</li> <li>the second parameter is a floating point value going from 0 (included) to 5 (excluded);</li> <li>the third and last parameter is a boolean value that can either be <code>True</code> or <code>False</code>.</li> </ul> <p>When passed to the optimization algorithm, PATATUNE will check that the lenght of the two lists is equal, warning the user in case of mismatch and using the lowest range. It will then check the types of the variable, throwing a warning in case of mismatch and using the most permissive type (<code>bool</code> &lt; <code>int</code> &lt; <code>float</code>).</p>"},{"location":"user_guide/#objective-function-definition","title":"Objective function definition","text":"<p>The user can use any function as objective function to evaluate in the optimization process.</p> <p>For each set of parameters, identifying a 'position' in the search space, the objective function will return a value, also called 'fitness'.</p> <p>PATATUNE can optimize the parameters against any number of objective functions.</p> <p>Two different methods can be identified in defining the functions:</p> <ul> <li>Objective functions that implements a method to evaluate a list of positions at once, returning a corresponding list of fitnesses</li> <li>Objective functions that implements a method to evaluate a single position at a time, returning the fitness of the single position</li> </ul> <p>PATATUNE allows to define these objective functions through the <code>Objective</code> class and it's subclasses.</p> <p>During the optimization, the <code>evaulate</code> function of the class will be called behaving differently based on its implementation</p>"},{"location":"user_guide/#objective","title":"Objective","text":"<p>The Objective class is the base class for defining objective functions and takes as argument a list of objective functions <code>[f1, f2, ...]</code>.</p> <p>In the evaluate method, all objective functions are executed as:</p> <pre><code>[f(positions) for f in objective_functions]\n</code></pre> <p>Each objective function is run once per iteration on all particle positions simultaneously.</p> <p>Input format: Each objective function receives a list of arrays with shape <code>(num_particles, num_parameters)</code>, where each row represents a position in the search space.</p> <p>Output format: Returns an array with shape <code>(num_particles, num_objectives)</code>, where each row contains the evaluated objective values for a particle.</p> <p>This approach is useful when:</p> <ul> <li>Objective functions implements their own way to handle multiple set of parameters</li> <li>Batch processing is implemented externally</li> <li>All particles can be evaluated simultaneously</li> </ul> <p>Example usage:</p> <pre><code>def f1(x):\n    return x[:, 0]**2\n\ndef f2(x):\n    return (x[:, 0] - 2)**2\n\nobjective = patatune.Objective([f1, f2])\n</code></pre>"},{"location":"user_guide/#elementwise-objective","title":"ElementWise Objective","text":"<p>The ElementWiseObjective class inherits from <code>Objective</code> and provides a way to evaluate objective functions element-wise, one particle at a time.</p> <p>Unlike the base <code>Objective</code> class where each function receives all positions at once, <code>ElementWiseObjective</code> calls each objective function individually for every particle position.</p> <p>The evaluate method iterates over each position and applies the objective functions:</p> <pre><code>[[f(position) for position in positions] for f in objective_functions]\n</code></pre> <p>This approach is useful when:</p> <ul> <li>The objective function is designed to work on a single parameter set at a time</li> <li>The evaluation will be vectorized by python</li> <li>Evaluations are independent and don't benefit from batch processing</li> </ul> <p>For example, defining a simple element-wise objective:</p> <pre><code>def f1(x):\n    return x[0]**2\n\ndef f2(x):\n    g = 1 + 9.0 / (len(x)-1) * sum(x[1:])\n    h = 1.0 - np.sqrt(f1 / g)\n    return g * h\n\nobjective = patatune.ElementWiseObjective([f1, f2])\n</code></pre> <p>The objective function receives a single parameter array <code>x</code> and returns a tuple of objective values <code>(f1, f2)</code>.</p>"},{"location":"user_guide/#asynchronous-objective-evaluation","title":"Asynchronous Objective evaluation","text":"<p>PATATUNE provides two classes for asynchronous objective function evaluation, enabling efficient parallel processing when dealing with computationally expensive evaluations or external services.</p>"},{"location":"user_guide/#asyncelementwiseobjective","title":"AsyncElementWiseObjective","text":"<p>The AsyncElementWiseObjective class evaluates objective functions asynchronously on each particle independently. This approach is useful when:</p> <ul> <li>Each evaluation is expensive and independent</li> <li>Evaluations can benefit from concurrent execution (I/O-bound operations, API calls, etc.)</li> <li>You want maximum parallelism without manual batching</li> </ul> <p>All objective functions must be defined with <code>async def</code> and the class automatically handles concurrent execution using <code>asyncio.gather</code>.</p> <p>Example usage:</p> <pre><code>async def async_objective_function(x):\n    f1 = x[0]\n    g = 1 + 9.0 / (len(x)-1) * sum(x[1:])\n    h = 1.0 - np.sqrt(f1 / g)\n    f2 = g * h\n    return [f1, f2]\n\nobjective = patatune.AsyncElementWiseObjective(async_objective_function)\n</code></pre>"},{"location":"user_guide/#batchobjective","title":"BatchObjective","text":"<p>The BatchObjective class provides asynchronous batch evaluation, where particles are grouped into batches before evaluation. This is particularly useful when:</p> <ul> <li>The evaluation system works more efficiently with batches</li> <li>You want to control resource consumption by limiting concurrent operations</li> <li>External systems have rate limits or batch processing capabilities</li> </ul> <p>The <code>BatchObjective</code> requires:</p> <ul> <li>Asynchronous objective functions: Functions must be defined with <code>async def</code></li> <li>Batch size: Parameter that controls how many particles are evaluated in each batch</li> </ul> <p>Example usage:</p> <pre><code>async def batched_evaluation(params):\n    # params is a list of parameter sets (one batch)\n    results = []\n    for p in params:\n        f1 = 4 * p[0]**2 + 4 * p[1]**2\n        f2 = (p[0] - 5)**2 + (p[1] - 5)**2\n        results.append([f1, f2])\n    return results\n\nobjective = patatune.BatchObjective(\n    [batched_evaluation],\n    batch_size=10\n)\n</code></pre> <p>The <code>BatchObjective</code> automatically splits the particle positions into batches of the specified size and evaluates them concurrently using <code>asyncio.gather</code>.</p>"},{"location":"user_guide/#multiple-objectives-definition","title":"Multiple objectives definition","text":"<p>The class determines the number of objectives based on the length of the list of objective_functions passed as argument, assuming that a single objective value is evaluated by each function.</p> <p>However, in case an objective function were to return more than one value, the user can specify the number of expected objectives returned with the optional <code>num_objectives</code> argument.</p> <p>Optionally the user can pass the names of the objectives in the <code>objective_names</code> argument, that will be used by the FileManager when saving the results of the optimization. If they are not passed as arguments, they default to <code>['objective_0','objective_1',...]</code>.</p> <p>Finally, the user can pass a callable in the <code>true_pareto</code> argument. This is a function that will return a list of points of size equal to the archive of optimal solution obtained after the optimization, with the fitnesses of each point.</p> <p>The argument is completely optional and used in measuring the GD and IGD metrics.</p> <pre><code>def zdt1(x):\n    f1 = x[0]\n    g = 1 + 9.0 / (len(x)-1) * sum(x[1:])\n    h = 1.0 - np.sqrt(f1 / g)\n    f2 = g * h\n    return [f1, f2]\n\ndef true_pareto(num_points):\n    f1 = np.linspace(0, 1, num_points)\n    f2 = 1 - np.sqrt(f1)\n    return np.array([f1, f2]).T\n\nobjective = patatune.ElementWiseObjective(zdt1, num_objectives=2, objective_names=['f1', 'f2'], true_pareto=true_pareto)\n</code></pre>"},{"location":"user_guide/#defining-the-direction-of-the-optimization","title":"Defining the direction of the optimization","text":"<p>By default, each objective is optimized to be minimized. To override this behaviour, the user can pass the <code>directions</code> argument as a list of strings (i.e. <code>['minimize', 'maximize', 'minimize']</code>), listing the optimization direction for each objective. If the number of objectives don't match the lenght of the strings, PATATUNE raises an error.</p> <pre><code>objective = patatune.ElementWiseObjective([efficiency_function, fake_rate_function], directions=['maximize', 'minimize'])\n</code></pre>"},{"location":"user_guide/#otimization-algorithm-configuration","title":"Otimization algorithm configuration","text":"<p>The Optimizer base class allows to define custom multi-objective optimization algorithm to be used in the same way by the user.</p> <p>Currently the library implements a Multi-Objective Particle Swarm Optimization (MOPSO) algorithm.</p>"},{"location":"user_guide/#mopso","title":"MOPSO","text":"<p>The MOPSO algorithm is a versatile optimization tool designed for solving multi-objective problems. It leverages the concept of swarm to navigate the search space and find optimal solutions.</p>"},{"location":"user_guide/#algorithm-overview","title":"Algorithm Overview","text":"<p>The implementation in the library is close to the one defined here:</p> <ul> <li>A swarm of particle is initialized in the parameters space</li> <li>The objective functions are evaluated for each particle</li> <li>Each particle is tested for dominance</li> <li>The dominant particles are added to the archive of optimal solutions</li> <li>Each particle updates its velocity and position based on its local best and a global best chosen from the archive</li> <li>The process is repeated for a given number of iterations</li> <li>At the end of the optimization, the archive of optimal solutions is returne</li> </ul>"},{"location":"user_guide/#basic-configuration","title":"Basic Configuration","text":"<p>The MOPSO class can be configured through several parameters:</p> <ul> <li>Objective: MOPSO can optimize virtually any objective function defined by the user as an instance of the Objective class or its subclasses.</li> <li>Boundary Constraints: Users has to define the lower and upper bounds of the parameters to optimize, and the name of the parameters.</li> <li>Swarm Size: The user can define the number of particles in the swarm with the <code>num_particles</code> parameter.</li> </ul> <pre><code>mopso = patatune.MOPSO(\n    objective=objective,\n    lower_bounds=[0.0] * 30,\n    upper_bounds=[1.0] * 30,\n    num_particles=100\n)\n</code></pre>"},{"location":"user_guide/#hyperparameters","title":"Hyperparameters","text":"<p>The behavior of the MOPSO algorithm can be fine-tuned through three hyperparameters:</p> <ul> <li>Inertia Weight: Control the inertia of the particles, influencing their tendency to continue moving in the same direction.</li> <li>Cognitive Coefficients: Control the influence of the particle's own best-known position on its movement.</li> <li>Social Coefficients: Control the influence of the swarm's best-known position on the particle's movement.</li> </ul> <p>Higher inertia weight will lead to particles maintaining their velocity, promoting exploration of the search space, while lower inertia weight will encourage particles to focus on their local best solutions.</p> <p>Higher value of the social coefficient will lead the particles to be more attracted towards the global best solution found by the swarm, promoting exploration but leading to potentially lower diversity in the solutions.</p> <p>Higher value of the cognitive coefficient will lead to a more exploitative behavior, meaning that the particles will be more likely to refine their search in the vicinity of known good solutions, potentially leading to faster convergence but risking getting stuck in local optima.</p>"},{"location":"user_guide/#topology-strategies","title":"Topology Strategies","text":"<p>The choice of the <code>global_best</code> particle from the archive can be configured through the <code>topology</code> parameter:</p> <ul> <li><code>random</code>: the <code>global_best</code> is chosen randomly from the archive</li> <li><code>round_robin</code>: the <code>global_best</code> is chosen in round robin fashion from the archive</li> <li><code>lower_weighted_crowding_distance</code> and <code>higher_weighted_crowding_distance</code>: the <code>global_best</code> is chosen based on the crowding distance of the particles in the archive, favoring less crowded areas or more crowded areas respectively.</li> </ul> <p>Using the crowding distance can help to maintain diversity in the solutions found by the swarm, preventing premature convergence to a single solution, however it is computationally more expensive. Using the random or round robin strategies is computationally cheaper, but can lead to less diverse solutions.</p>"},{"location":"user_guide/#setting-the-initial-particle-positions","title":"Setting the initial particle positions","text":"<p>The initial position of the particles can be defined through the <code>initial_particle_position</code> parameter and the <code>default_point</code> parameter:</p> <ul> <li><code>random</code> uniform distribution</li> <li><code>gaussian</code> distribution around the <code>default_point</code></li> <li>all in the <code>lower_bounds</code> or <code>upper_bounds</code> of the parameter space</li> </ul> <p>Setting the <code>default_point</code> parameter with any option other than <code>gaussian</code> will ensure that at least one particle starts from that position. The gaussian distribution will center the particles around the <code>default_point</code>, with a standard deviation equal to one fourth of the distance between the lower and upper bounds. The particles will be clamped to stay within the defined bounds.</p> <p>The choice of the initial position can influence the convergence speed and the variety of solutions found by the swarm.</p> <pre><code>mopso = patatune.MOPSO(\n    objective=objective,\n    lower_bounds=[0.0] * 30,\n    upper_bounds=[1.0] * 30,\n    num_particles=100,\n    initial_particle_position='gaussian',\n    default_point=[0.5] * 30\n)\n</code></pre>"},{"location":"user_guide/#additional-features","title":"Additional Features","text":"<ul> <li>Exploration Mode: An optional exploration mode enables particles to scatter from their position when they don't improve for a given number of iterations</li> </ul> <p>Exploration mode can help to escape local optima and explore new areas of the search space, potentially leading to better overall solutions. However it's implementation is still experimental and should be used with caution.</p> <ul> <li>Limit on Archive Size: The archive of optimal solutions can be limited in size, removing the most crowded solutions when the limit fixed with the <code>max_pareto_length</code> is reached.</li> </ul> <p>See the API reference for additional information on the parameters.</p>"},{"location":"user_guide/#running-the-optimization","title":"Running the optimization","text":"<p>MOPSO can be run using the <code>optimize</code> method for a specific number of iterations, or it can also be run interactively by calling the <code>step</code> function to perform a single iteration.</p> <pre><code>mopso.optimize(num_iterations=200)\n</code></pre> <p>If the <code>exploring_particles</code> option is enabled, the user can pass the <code>max_iterations_without_improvement</code> parameter to define after how many iterations without improvement a particle should be scattered in the search space.</p> <pre><code>mopso.optimize(num_iterations=200, max_iterations_without_improvement=10)\n</code></pre>"},{"location":"user_guide/#utilities","title":"Utilities","text":"<p>PATATUNE provides several utilities to adapt to the user workflow and environment.</p>"},{"location":"user_guide/#file-manager","title":"File Manager","text":"<p>The FileManager class provides functionalities to manage file saving and loading during the optimization process.</p> <p>If the <code>FileManager.saving_enabled</code> flag is set to <code>True</code>, the state of the optimizer will be saved in the working directory specified in the <code>FileManager.working_directory</code>.</p> <p>The <code>FileManager</code> will create the directory if it does not exist.</p> <p>The <code>FileManager</code> supports different file formats for saving the state of the optimizer, that can be enabled or disabled through the corresponding flags <code>saving_pickle_enabled</code>, <code>saving_json_enabled</code>, <code>saving_csv_enabled</code>, and <code>saving_zarr_enabled</code>.</p> <p>For example, in <code>MOPSO</code>, if the correct flags are set, the following files will be created in the working directory at each saving step:</p> <ul> <li>a <code>checkpoint/pareto_front.csv</code> file containing the current archive of optimal solutions with the parameters and objective values in floating point representation with 18 decimals, with comma delimiter. If <code>FileManager.headers_enabled</code> is set to <code>True</code>, a header row will be included with the parameter names and objective names.</li> <li>a <code>checkpoint/individual_states.csv</code> file containing the current state of each particle in the swarm, with the parameters and velocities in floating point representation with 18 decimals, with comma delimiter. If <code>FileManager.headers_enabled</code> is set to <code>True</code>, a header row will be included with the parameter names and velocity names (<code>velocity_&lt;parameter_name&gt;</code>).</li> <li>a <code>checkpoint/mopso.pkl</code> file containing the full MOPSO object serialized with <code>dill</code>.</li> </ul> <p>At the end of all iterations, a <code>checkpoint/mopso.zip</code> file will be created containing the history of the optimization process saved at each saving step as a zarr archive. The archive will contain a group for each iteration named <code>iteration_&lt;iteration_number&gt;</code>, containing a dataset <code>data</code> with the parameters and fitnesses of all particles at that iteration, and a group <code>pareto_front</code> containing a dataset <code>data</code> with the parameters and fitnesses of the Pareto front particles. Along with the datasets, the archive will contain attributes with the parameter names, objective names, lower bounds and upper bounds of the optimization process.</p> <p>If the <code>FileManager.loading_enabled</code> flag is set to <code>True</code>, the optimizer will attempt to load its state from the working directory at the beginning of the optimization process, using the latest saved <code>checkpoint/mopso.pkl</code> file.</p> <p>This allows to resume an optimization process from the last saved state.</p>"},{"location":"user_guide/#random","title":"Random","text":"<p>PATATUNE relies on random number generation. To make sure to obtain reproducible results an helper function allows to set the seed for every random generation performed by the algorithm:</p> <pre><code>patatune.Randomizer.rng = np.random.default_rng(42)\n</code></pre>"},{"location":"user_guide/#logging","title":"Logging","text":"<p>You can configure the amount of logging information printed on terminal by passing a string to the setLevel function of the <code>patatune.Logger</code>:</p> <pre><code>patatune.Logger.setLevel('DEBUG')\n</code></pre> <p>The supported levels - from least to most verbose - are: <code>'ERROR'</code>, <code>'WARNING'</code>, <code>'INFO'</code>, <code>'DEBUG'</code></p>"}]}